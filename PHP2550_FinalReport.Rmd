---
title: "PHP2550 Final Report"
author: "Abraham Liu, Asghar Shah, Zhejia Dong"
date: "12/15/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE, results = 'hide'}
library(tidyverse)
library(knitr)
library(TSA)
library(forecast)
library(tscount)
library(kableExtra)
```

# Abstract 

Foodborne illness is responsible for a major burden of hospitalization, disability, and morbidity globally. One cause of foodborne illness is the pathogenic bacterium Listeria monocytogenes  (L. monocytogenes). Individuals consuming food contaminated with this bacterium may develop listeriosis, a rare but fatal condition, even with treatment. Given the dangers associated with the potential spread of L. monocytogenes, efforts to estimate or predict potential cases are critical. These efforts may be useful with respect to devoting adequate resources in areas that may have high predicted counts, or potentially investigating isolation sources that are associated with increased counts of the bacterium. Given these benefits, we sought to model potential cases of  L. monocytogenes. To perform this, we first acquired isolated source data from the NCBI Pathogen Detection Isolation Browser website. We filtered to only include L. monocytogenes, made groups for the most common genetically related clusters, and made a variable for the isolation source. We also produced a variable for the season based on the isolate creation date. We performed time-series analysis in the form of a poisson autoregressive model to predict cases of L. monocytogenes. We also fitted a negative binomial regression to assess whether it could assist with overdispersion. We determined that the model that includes SNP cluster, season, and isolation sources to perform the best with respect to model selection metrics AIC and MSE (This model had an associated AIC1 of 26624.50 and MSE1 of 125143.38). Autoregressive on one past observation seemed to be the best. When comparing the poisson autoregressive models with negative binomial, we determined that the negative binomial model had a better fit and also accoutned for overdispersion, but prediction-wise was less accurate on data with low counts. Our analyses were, among other aspects, limited by the nature of the NCBI Pathogen Detection Isolation Browser website. The dates reported are not the actual dates associated with the time of the case, rather it is the time that the isolate was inputted into the database. In light of this limitation, we can conclude that the cluster, season, and isolation source model is able to forecast cases of L. monocytogenes with some degree of accuracy, although it can be improved upon. Future improvements can include weather variables along with an “outbreak” warning system to notify the model user of times when potential cases may rise abruptly. These additions would contribute to the general applicability and utility of the model.  

# Background 

Foodborne illness can be caused by a myriad of factors, including the contamination by harmful chemicals$^1$ or pathogenic microbes such as bacteria, viruses, and parasites$^2$. The Centers for Disease Control estimate that foodborne illness causes 48 million Americans to get sick, 128,000 to be hospitalized, and 3,000 die each year$^3$.  A World Health Organization (WHO) report on the global burden of foodborne diseases (2007-2015) estimated that 31 global hazards caused 600 (95% CI 420–960) million foodborne illnesses and estimated 420,000 (95% 310,000–600,000) deaths in 2010$^4$. Moreover, they report that the estimated burden of these 31 global hazards was 33 (95% 25-46) million disability-adjusted life years (DALYS) in 2010 with a disproportionate burden among children under 5 (40%).  

Listeriosis is an infection typically caused by eating food contaminated with the pathogenic bacterium Listeria monocytogenes (L. monocytogenes)^$5$.  Listeriosis contributes to the burden of foodborne illness worldwide with serious clinical manifestations.  A systematic review and meta-analysis of the global burden of Listeriosis estimated that in 2010 L. monocytogenes caused 23,150 illnesses worldwide, 5463 deaths, and 172,823 DALYS (95% CI 44,079-676,465)$^6$. Several documented outbreaks of listeriosis in the United States have been reported in the literature. Some recent examples include varied food sources of origin including avocados$^7$, packaged leafy green salads$^8$, and soft cheeses$^9$ .

Given the burden of foodborne illness, particularly those caused by Listeria monocytogenes, strategies to prevent transmission, surveil the presence of pathogens, and assess risk have been applied. Whole genome sequencing (WGS) is an increasingly common method of pathogen surveillance in the context of foodborne illness$^{10}$. This method has been applied in France where isolates of L. monocytogenes were sequenced, resulting in the detection of clusters of related isolates$^{11}$. WSG of L. monocytogenes has also been used to identify the international spread of multiple sublineages of related L. monocytogenes, and the identification of genetically related isolates internationally which may indicate transmission across countries$^{12}$. Moura et. al were able to develop and validate a genome-wide genotyping system through WGS. Through WGS of clinical isolates from varying geographic locations, they were able to assess international transmission events. Machine learning based classification approaches have also been applied to predict food source attribution of L. monocytogenes$^{13}$. Tanui et. al’s final classification model predicted that 17.5% of clinical isolates were derived from dairy, 32.5% to fruits, 18.8% to vegetables, 14.3% to greens (leafy), 9.7% to meat, and 4.6% to poultry.  Thus, we can see that models have been used to assess the spread and source origin of Listeria monocytogenes.

Aside from the previously mentioned methods, time series regression (TSR) modeling and analysis have been used to detect seasonality and weather predictors of infection episodes$^{14}$. This TSR modeling has also been used in the context of assessing Listeria seasonality$^{15}$. For example, Simpson et. al used negative binomial harmonic regression models on isolate counts from FoodNet to assess the peak timing of Listeria across states in the US. These models have been used to assess relationships between predictors in the environment and adverse health outcomes$^{16}$. There has also been a recent uptick in the number of TSR models aiming to forecast the spread of infections positive for COVID-19$^{17,18}$.

Imai et. al provide a general overview of the TSR for infectious disease and weather$^{14}$. As they describe it, TSR analysis seeks to understand how time-varying variables (i.e. temperature) explain variation in an outcome series (i.e. daily counts of a disease). The Poisson model is typically chosen in these cases and may be written as: 

$$Y_t \sim \text{Poisson}(\mu_t)$$
$$log(\mu_t) = \beta_0 + \beta x_t + \sum_p \beta_pz_{p,t} + f(t)$$

In this model,  is the smoothing function of time,  is the variable that changes with time, and the beta terms are the regression coefficients. de Noordhout et. al sought to forecast cases of Listeriosis in Belgium using time series analysis$^{19}$. Similar to the methods described by Imai et. al, de Noordhout’s study applied a Poisson autoregressive (PAR) model for listeriosis. They developed this listeriosis model through counting monthly cases from January 2011 through December 2013. The authors made the decision to apply both a time series model and a static prediction model, given the short time series. Moreover, they were not able to assess seasonal patterns for this same reason. Autocorrelation is a measure of the relationship between two values of the same variable given a lag in time.  The model used to fit the data was PAR(p), where they tested p with integer values ranging from 1 to 4. They then chose (PAR(2)) as the best fitted model based on the significance of the estimated autoregressive coefficients. They made predictions through simulation using the mean prediction function described by Brandt and Williams$^{20}$. Through this Poisson autoregressive model for listeriosis, they were able to estimate the DALYs associated with Listeriosis in 2012 and 2014, 208 (95% 192-226) and 252 (95% CI 200-307),  respectively. 

This project builds on the body of literature aiming to model the occurrence of cases of infectious disease, specifically that of foodborne Listeriosis.  Given the burden of Listeria globally and in the US, it is important for researchers, public health administrators, and clinicians to understand temporal trends in cases of Listeria. This information would be valuable to attain since it could assist in resource allocation (i.e. food inspectors) and putting in place measures to mitigate pathogen spread in areas predicted to be high-transmission zones. To achieve this, we applied TSR, in the form of Poisson autoregressive and negative binomial regression modeling on the NCBI dataset with the outcome of interest being cases of Listeria.

# Methods

## Data Source

Listeria isolate data was acquired through downloading from the NCBI (National Center for Biotechnology Information) Pathogen Detection Beta Browser in Oct 2022. This publicly available data source is a repository for bacterial and fungal genomic sequencing data, SNP clusters, and meta data sourced from surveillance and research investigations. Isolates are included into the repository on a rolling-basis when researchers and public health agencies sequence the samples and submit the data to NCBI. NCBI is responsible for performing analyses on the sequences to assist with investigating outbreaks by comparing the submitted sequence with related sequences found in the database 

## Variable Definitions

Several variables from the NCBI dataset were used in this study and understanding the variable definitions is crucial for avoiding erroneous conclusions. All definitions are derived from the NCBI Pathogen Detection Isolation Browser website. The creation date was the date when the isolate was first seen by the Pathogen Detection System. It is important to note that these are dates associated with when the scientists report the isolates and when they are necessarily found. The SNP cluster .... The isolation source describes the source of where the biological sample came from (i.e. physical, environment, etc). The SNP cluster represents a collection of biological isolates whose genomes are closely related. 

## Data Preprocessing

The data was heavily preprocessed prior to analysis being conducted. Date data was converted into a year-week format and we computed a count for the number of cases for each year-week grouping during the time elapsed from the first isolate to the last isolate date. We created a vector of these values of reported cases for each weekly period. We made five groups for the top SNP Clusters. We attempted to include more SNP clusters, but ran into issues of model overfitting. We also created a group for the four most common isolation sources (i.e. meat, seafood, dairy, and blood). We also incorporated a variable depending on the isolate date (i.e. spring, summer, fall, winter). Our time series data itself was not filtered. Below is a time series plot of our cases from 2014 to 2022, We can see that there are very big spikes between 2019 and 2022 that appear without warning, which could be problematic to model.

```{r, echo = FALSE}
#load in dataset
food<- read.csv("C:/Users/abrah/Downloads/isolates.csv")
#view(food)
```

```{r, echo = FALSE}
#initiate new dataset for modification
ts_df <- food
#add a new date variable with the correct format
ts_df$Date <- sapply(1:nrow(ts_df), function(x){
  str_split(ts_df$Create.date[x],"T")[[1]][1]
})
ts_df$Date <- as.Date(ts_df$Date)

dates <- sort(unique(ts_df$Date))

#filter out the first few years
dates <- dates[27:length(dates)]

ts_df <- ts_df[ts_df$Date %in% dates,]

full_calender <- seq(as.Date("2014-01-02"), as.Date("2022-10-18"), by = "days")
ts_df$week_num <- rep(1, nrow(ts_df))
for (i in 0:(ceiling(length(full_calender)/7)-1)){
  ts_df$week_num[ts_df$Date %in% full_calender[(1+7*i):(7+7*i)]] <- i+1
}
num_weeks <- max(ts_df$week_num)

#label of season for each week in a year
season_year <- c(rep("Winter", 9), rep("Spring", 13), rep("Summer", 13), rep("Fall", 13), rep("Winter", 4))
#do this for 9 years, then only take the weeks applicable to our study 
season_var <- c(rep(season_year, 9))[1:num_weeks]
```

```{r, echo = FALSE}
overall_ts <- rep(0, num_weeks)
for (j in 1:num_weeks){
  overall_ts[j] <- nrow(ts_df[ts_df$week_num == j,])
}
e <- data.frame(weeks = 1:num_weeks, Cases = overall_ts)
ggplot(e, aes(x = weeks, y = Cases)) + geom_point() + geom_line() + 
  labs(title = "Time Series of Overall Cases") + 
  scale_x_continuous(name = "Time (in Weeks)", breaks = c(1, 53, 105, 157, 209, 261, 313, 365, 417), 
                     labels = c("2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022"))
```

## Time Series Modelling

We incorporated 6 models when using Poisson Time Series Regression with an identity link. The model's definition is the following:

$$Z_t|\mathcal F_t \sim \text{Poisson}(\nu_t)$$
where $Z_t$ represents the listeria cases at timepoint t, $\mathcal F_t$ represents the covariate data (whether it be SNP clusters, isolation sources, or seasonal related data) up to timepoint $t-1$ as well as one past (most recent) observation to autoregress on, and $\nu_t$ represents the average value of $Z_t$. The linear predictor of our models aim to estimate $\nu_t$ for each timepoint $t$. The formula for $\nu_t$ is the following:

$$\nu_t = \beta_0 + \beta_1Z_{t-1} + \eta_1X_{t,1} + ... + \eta_rX_{t,r}$$
where $\beta_0$ represents the intercept, $\beta_1$ the coefficient for the first autoregressed observation, and $\eta_1$ to $\eta_r$ the coefficients for each of our covariate variables. 

Using this, we have developed 6 main models: The first model with only the SNP clusters as the covariates, the second model with SNP clusters interacting with the season variable, the third model with only the 4 isolate sources as the covariates, the fourth model with the isolate sources interacting with the season variable, the fifth model with both SNP clusters and isolate sources as the covariates, and the 6th model with SNP clustered and isolate sources interacting with the season variable. 

Model selection was based on comparisons of AIC (Akaike information criterion)  and MSE (mean squared error). AIC is an estimate that is used to compare between models and that penalizes over fitting. A lower AIC is considered better. MSE is a metric used to assess the quality of the predictions and it describes the distance between observed and predicted values. The MSE in our case is calculated through formula $\frac 1n \sum_{i=1}^n(\text{observed}_i - \text{predicted}_i)^2$.The lower the MSE, the more accurate our model is in prediction. For the purpose of getting stable MSE estimates, the predicted $\nu_t$ value was used as the predicted value for each time step. When fitting the model, we used the data from 2014 to the end of 2020 as our training set, and forecasted the data for 2021 to calculate our MSE. Through comparing the AIC and MSE combinations for the varying models, we were able to decide which models to select for forecasting. 

After initial model selection,we tested autoregression of up to 3 observations to see if it helped in model fit. The linear predictor for two autoregressed past observations becomes:

$$\nu_t = \beta_0 + \beta_1Z_{t-1} + \beta_2Z_{t-2} + \eta_1X_{t,1} + ... + \eta_rX_{t,r}$$
and the linear predictorfor three autoregressed past observations becomes: 

$$\nu_t = \beta_0 + \beta_1Z_{t-1} + \beta_2Z_{t-2} + \beta_3Z + \eta_1X_{t,1} + ... + \eta_rX_{t,r}$$

After determining our best performing model, we analyzed the performance of this model function when fitting new models based on whether we use the poisson distribution or negative binomial distribution and whether we autoregressed the negative binomial model on a past conditional mean or not. We consider the negative binomial distribution for potential overdispersion problems, as seen with the highly fluctuating spikes within 2019 to 2021. For past conditional means, we selected the case outcome with the highest frequency, the second highest frequency, and the rounded average case value to compare. 

The definition of the Negative binomial model becomes the following:

$$Z_t|\mathcal F_t \sim \text{NegBin}(\nu_t,\phi)$$
where $\phi$ represents the dispersion parameter. 

The linear predictor when incorporating a past mean becomes the following:

$$\nu_t = \beta_0 + \beta_1Z_{t-1} + \alpha_1\nu_{t-1} + \eta_1X_{t,1} + ... + \eta_rX_{t,r}$$
where $\alpha_1$ represents the coefficient for the conditional mean of the previous step. 

# Results

Prior to describing the results pertaining to model building, selection, and forecasting, it is important to have a general understanding of the underlying data. The data set used for analysis is structured row-wise and consists of 54,246 isolates. The top 5 SNP clusters by count were PDS000000366.504 (n=1744), PDS000025311.254 (1253),  PDS000024989.120 (992), PDS000024645.152 (859), and PDS000024656.185 (857). The date range for the included isolates was 2014-01-02 to 2022-10-18. The isolation source groups we used for categorization included meat sources (n=2194), dairy sources (1776), sea food sources (844), and blood sources (3151).  

```{r, echo = FALSE}
a <- as.data.frame(table(food$SNP.cluster)) 
sorted_Clusters<- a[order(-a$Freq),] 
total <- sum(sorted_Clusters$Freq)
#sum(sorted_Clusters$Freq[sorted_Clusters$Freq > 100])/total
#sorted_Clusters$Var1[sorted_Clusters$Freq > 500]
```

```{r, echo = FALSE}
cluster_matrix <- matrix(0, nrow = num_weeks, ncol = 5)
#grab top 5 (excluding the unknown strains)
for (i in 2:6){
  for (j in 1:num_weeks){
    cluster_matrix[j,i-1] <- nrow(ts_df[ts_df$week_num == j & ts_df$SNP.cluster == sorted_Clusters$Var1[sorted_Clusters$Freq > 100][i],])
  }
}
```

```{r, echo = FALSE}
pois_cluster <- tsglm(ts = overall_ts[1:364], model = list(past_obs = 1), xreg = cluster_matrix[1:364,], distr = "poisson")

#summary(pois_cluster)
```

```{r, echo = FALSE}
MSE_calc <- function(covariates, mod_coef) {
  set.seed(0)
  #initialize MSE vector 
  MSE_vals <- c()
  #get MSE values of the forecasts for the next 6 months
  next_y <- c(overall_ts[364])
  for (j in 0:25) {
    mod_lambda <- mod_coef %*% c(1, next_y[j+1], covariates[365+j,])
    MSE_vals <- c(MSE_vals, (overall_ts[365+j] - mod_lambda)^2)
    next_y <- c(next_y, mod_lambda)
  }
  return(sum(MSE_vals)/length(MSE_vals))
}
cluster_MSE <- MSE_calc(cluster_matrix, coef(pois_cluster))
#cluster_MSE
```

```{r, echo = FALSE}
season_factor <- as.numeric(as.factor(season_var))
#get covariates of cluster variables, season variable, and interaction between the cluster variables and season
cseason_matrix <- cbind(cluster_matrix, as.factor(season_var), cluster_matrix * season_factor)

pois_cseason <- tsglm(overall_ts[1:364], model = list(past_obs = 1), xreg = cseason_matrix[1:364,], distr = "poisson")

summary(pois_cseason)
```

```{r, echo = FALSE}
cseason_MSE <- MSE_calc(cseason_matrix, coef(pois_cseason))
#cseason_MSE
```


```{r, echo = FALSE}
b <- as.data.frame(table(food$Isolation.source)) 
sorted_sources<- b[order(-b$Freq),] 
iso_source <- unique(b$Var1)

#run unique on meat source because there can be overlap (like having meat and beef in the source name)
meat_source <- unique(c(grep("meat", iso_source, value=TRUE), grep("chicken", iso_source, value=TRUE), grep("pork", iso_source, value=TRUE), grep("beef", iso_source, value=TRUE)))
dairy_source <- unique(c(grep("milk", iso_source, value=TRUE), grep("cheese", iso_source, value=TRUE), grep("ice cream", iso_source, value=TRUE), grep("dairy", iso_source, value=TRUE)))
seafood_source <- unique(c(grep("seafood", iso_source, value=TRUE), grep("salmon", iso_source, value=TRUE), grep("tuna", iso_source, value=TRUE), grep("fish", iso_source, value=TRUE), grep("lobster", iso_source, value=TRUE), grep("shrimp", iso_source, value=TRUE), grep("clam", iso_source, value=TRUE), grep("crab", iso_source, value=TRUE)))
blood_source <- grep("blood", iso_source, value=TRUE)

#meat source has entries from seafood, so we need to get rid of it
meat_seafood <- unique(c(c(grep("seafood", meat_source, value=TRUE), grep("salmon", meat_source, value=TRUE), grep("tuna", meat_source, value=TRUE), grep("fish", meat_source, value=TRUE), grep("lobster", meat_source, value=TRUE), grep("shrimp", meat_source, value=TRUE), grep("clam", meat_source, value=TRUE), grep("crab", meat_source, value=TRUE))))

meat_source <- meat_source[!(meat_source %in% meat_seafood)]
```

```{r, echo = FALSE}
source_matrix <- matrix(0, nrow = num_weeks, ncol = 4)
#grab top 5 (excluding the unknown strains)

for (j in 1:num_weeks){
  source_matrix[j,1] <- nrow(ts_df[ts_df$week_num == j & ts_df$Isolation.source %in% meat_source,])
  source_matrix[j,2] <- nrow(ts_df[ts_df$week_num == j & ts_df$Isolation.source %in% seafood_source,])
  source_matrix[j,3] <- nrow(ts_df[ts_df$week_num == j & ts_df$Isolation.source %in% dairy_source,])
  source_matrix[j,4] <- nrow(ts_df[ts_df$week_num == j & ts_df$Isolation.source %in% blood_source,])
}
pois_source <- tsglm(overall_ts[1:364], model = list(past_obs = 1), xreg = source_matrix[1:364,], distr = "poisson")

#summary(pois_source)
```

```{r, echo = FALSE}
source_MSE <- MSE_calc(source_matrix, coef(pois_source))
#source_MSE
```

```{r, echo = FALSE}
#get covariates of source variables, season variable, and interaction between the source variables and season
isoseason_matrix <- cbind(source_matrix, as.factor(season_var), source_matrix * season_factor)

pois_isoseason <- tsglm(overall_ts[1:364], model = list(past_obs = 1), xreg = isoseason_matrix[1:364,], distr = "poisson")

#summary(pois_isoseason)
```

```{r, echo = FALSE}
isoseason_MSE <- MSE_calc(isoseason_matrix, coef(pois_isoseason))
#isoseason_MSE
```

```{r, echo = FALSE}
#get covariates of cluster variables and source variables
isocluster_matrix <- cbind(cluster_matrix, source_matrix)

pois_isocluster <- tsglm(overall_ts[1:364], model = list(past_obs = 1), xreg = isocluster_matrix[1:364,], distr = "poisson")

#summary(pois_isocluster)
```

```{r, echo = FALSE}
isocluster_MSE <- MSE_calc(isocluster_matrix, coef(pois_isocluster))
#isocluster_MSE
```

```{r, echo = FALSE}
#get covariates of cluster variables and source variables, season variable, and the interaction between cluster + seasonal and source + seasonal
all_matrix <- cbind(cluster_matrix, source_matrix, as.factor(season_var), cluster_matrix * season_factor, source_matrix * season_factor)

pois_all <- tsglm(overall_ts[1:364], model = list(past_obs = 1), xreg = all_matrix[1:364,], distr = "poisson")

#summary(pois_all)
```

```{r, echo = FALSE}
all_MSE <- MSE_calc(all_matrix, coef(pois_all))
#all_MSE
```

Below is our table that lists the AIC and MSE of each of the 6 initial poisson models we fitted. Although it's a bit strange that the model with isolation source variables only and the model with isolation source variables interacting with the season variable had a high AIC and a low MSE, this could indicate that the model was overfitted, especially since the AIC better indicates fit than the MSE. Overall, it's clear to see that the 6th model incorporating cluster variables interacting with season and isolation source variables interacting with season had the best model fit, with the lowest AIC (13473.30) and the lowest MSE (4056.937).

```{r, echo = FALSE}
models <- c("Cluster Variables", "Cluster with Seasons", "Source Variables", "Source with Seasons", "Cluster and Source", "Cluster, Source, and Seasons")
AIC_vals <- c(AIC(pois_cluster),AIC(pois_cseason),AIC(pois_source),AIC(pois_isoseason),AIC(pois_isocluster), AIC(pois_all))
meanmse <- c(cluster_MSE,cseason_MSE,source_MSE,isoseason_MSE,isocluster_MSE,all_MSE)
#medianmse <- c(median(cluster_MSE),median(cseason_MSE),median(source_MSE),median(isoseason_MSE),median(isocluster_MSE),median(all_MSE))
#sdmse <- c(sd(cluster_MSE),sd(cseason_MSE),sd(source_MSE),sd(isoseason_MSE),sd(isocluster_MSE),sd(all_MSE))
data.frame(Models = models, AIC = AIC_vals, MSE = meanmse) %>%
  kbl() %>%
  kable_styling()
```

```{r, echo = FALSE}
#final <- tsglm(overall_ts[1:364], model = list(past_obs = 1), xreg = all_matrix[1:364,], distr = "poisson")
```

```{r, echo = FALSE}
set.seed(0)
#m_counts <- c(overall_ts[312:364])
#for (i in 364:415){
#  m_counts <- c(m_counts, rpois(1,c(1, m_counts[i-311], all_matrix[i,]) %*% coef(final)))
#}
#obs_counts <- c(overall_ts[312:416])


#ts_final <- data.frame(Weeks = rep(312:416,2), Cases = c(m_counts, obs_counts), Models = c(rep("Cluster, Source, and Seasons", 105), rep("Observed", 105)))

#ggplot(ts_final, aes(x = Weeks, y = Cases, color = Models, groups = Models)) + 
#  geom_point() + geom_line() + labs(title = "Forecasted Cases with Observed") + 
#  theme(legend.position = "bottom") + 
#  scale_x_continuous(name = "Time (in Weeks)", breaks = c(1, 53, 105, 157, 209, 261, 313, 365), 
#                     labels = c("2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021"))
#ggsave(filename = "ts_plot.png", plot = ggplot(ts_final, aes(x = Weeks, y = Cases, color = Models, groups = Models)) + 
#  geom_point() + geom_line() + labs(title = "Forecasted Cases with Observed") + 
#  theme(legend.position = "bottom")) + 
#  scale_x_continuous(name = "Time (in Weeks)", breaks = c(1, 53, 105, 157, 209, 261, 313, 365), 
#                     labels = c("2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021"))
```

```{r, echo = FALSE}
pois_cluster2 <- tsglm(ts = overall_ts[1:364], model = list(past_obs = c(1,2)), xreg = cluster_matrix[1:364,], distr = "poisson")

#summary(pois_cluster2)
```

```{r, echo = FALSE}
MSE_calc2 <- function(covariates, mod_coef) {
  set.seed(0)
  #initialize MSE vector 
  MSE_vals <- c()
  #get MSE values of the forecasts for the next 6 months
  next_y <- c(overall_ts[363], overall_ts[364])
  for (j in 0:25) {
    mod_lambda <- mod_coef %*% c(1, next_y[j+2], next_y[j+1], covariates[365+j,])
    MSE_vals <- c(MSE_vals, (overall_ts[365+j] - mod_lambda)^2)
    next_y <- c(next_y, mod_lambda)
  }
  return(sum(MSE_vals)/length(MSE_vals))
}
cluster_MSE2 <- MSE_calc2(cluster_matrix, coef(pois_cluster2))
#cluster_MSE2
```


```{r, echo = FALSE}
pois_cseason2 <- tsglm(overall_ts[1:364], model = list(past_obs = c(1,2)), xreg = cseason_matrix[1:364,], distr = "poisson")

#summary(pois_cseason2)
```

```{r, echo = FALSE}
cseason_MSE2 <- MSE_calc2(cseason_matrix, coef(pois_cseason2))
#cseason_MSE2
```

```{r, echo = FALSE}
pois_source2 <- tsglm(overall_ts[1:364], model = list(past_obs = c(1,2)), xreg = source_matrix[1:364,], distr = "poisson")

#summary(pois_source2)
```

```{r, echo = FALSE}
source_MSE2 <- MSE_calc2(source_matrix, coef(pois_source2))
#source_MSE2
```

```{r, echo = FALSE}
pois_isoseason2 <- tsglm(overall_ts[1:364], model = list(past_obs = c(1,2)), xreg = isoseason_matrix[1:364,], distr = "poisson")

#summary(pois_isoseason2)
```

```{r, echo = FALSE}
isoseason_MSE2 <- MSE_calc2(isoseason_matrix, coef(pois_isoseason2))
#isoseason_MSE2
```

```{r, echo = FALSE}
pois_isocluster2 <- tsglm(overall_ts[1:364], model = list(past_obs = c(1,2)), xreg = isocluster_matrix[1:364,], distr = "poisson")

#summary(pois_isocluster2)
```

```{r, echo = FALSE}
isocluster_MSE2 <- MSE_calc2(isocluster_matrix, coef(pois_isocluster2))
#isocluster_MSE2
```

```{r, echo = FALSE}
pois_all2 <- tsglm(overall_ts[1:364], model = list(past_obs = c(1,2)), xreg = all_matrix[1:364,], distr = "poisson")

#summary(pois_all2)
```

```{r, echo = FALSE}
all_MSE2 <- MSE_calc2(all_matrix, coef(pois_all2))
#all_MSE2
```

```{r, echo = FALSE}
models <- c("Cluster Variables", "Cluster with Seasons", "Source Variables", "Source with Seasons", "Cluster and Source", "Cluster, Source, and Seasons")
AIC_vals2 <- c(AIC(pois_cluster2),AIC(pois_cseason2),AIC(pois_source2),AIC(pois_isoseason2),AIC(pois_isocluster2), AIC(pois_all2))
mse2 <- c(cluster_MSE2,cseason_MSE2,source_MSE2,isoseason_MSE2,isocluster_MSE2,all_MSE2)
#medianmse <- c(median(cluster_MSE),median(cseason_MSE),median(source_MSE),median(isoseason_MSE),median(isocluster_MSE),median(all_MSE))
#sdmse <- c(sd(cluster_MSE),sd(cseason_MSE),sd(source_MSE),sd(isoseason_MSE),sd(isocluster_MSE),sd(all_MSE))
#data.frame(Models = models, AIC = AIC_vals2, MSE = mse2) %>%
#  kbl() %>%
#  kable_styling()
```

```{r, echo = FALSE}
pois_cluster3 <- tsglm(ts = overall_ts[1:364], model = list(past_obs = c(1,2,3)), xreg = cluster_matrix[1:364,], distr = "poisson")

#summary(pois_cluster3)
```

```{r, echo = FALSE}
MSE_calc3 <- function(covariates, mod_coef) {
  set.seed(0)
  #initialize MSE vector 
  MSE_vals <- c()
  #get MSE values of the forecasts for the next 6 months
  next_y <- c(overall_ts[362], overall_ts[363], overall_ts[364])
  for (j in 0:25) {
    mod_lambda <- mod_coef %*% c(1, next_y[j+3], next_y[j+2], next_y[j+1], covariates[365+j,])
    MSE_vals <- c(MSE_vals, (overall_ts[365+j] - mod_lambda)^2)
    next_y <- c(next_y, mod_lambda)
  }
  return(sum(MSE_vals)/length(MSE_vals))
}
cluster_MSE3 <- MSE_calc3(cluster_matrix, coef(pois_cluster3))
#cluster_MSE3
```


```{r, echo = FALSE}
pois_cseason3 <- tsglm(overall_ts[1:364], model = list(past_obs = c(1,2,3)), xreg = cseason_matrix[1:364,], distr = "poisson")

#summary(pois_cseason3)
```

```{r, echo = FALSE}
cseason_MSE3 <- MSE_calc3(cseason_matrix, coef(pois_cseason3))
#cseason_MSE3
```

```{r, echo = FALSE}
pois_source3 <- tsglm(overall_ts[1:364], model = list(past_obs = c(1,2,3)), xreg = source_matrix[1:364,], distr = "poisson")

#summary(pois_source3)
```

```{r, echo = FALSE}
source_MSE3 <- MSE_calc3(source_matrix, coef(pois_source3))
#source_MSE3
```

```{r, echo = FALSE}
pois_isoseason3 <- tsglm(overall_ts[1:364], model = list(past_obs = c(1,2,3)), xreg = isoseason_matrix[1:364,], distr = "poisson")

#summary(pois_isoseason3)
```

```{r, echo = FALSE}
isoseason_MSE3 <- MSE_calc3(isoseason_matrix, coef(pois_isoseason3))
#isoseason_MSE3
```

```{r, echo = FALSE}
pois_isocluster3 <- tsglm(overall_ts[1:364], model = list(past_obs = c(1,2,3)), xreg = isocluster_matrix[1:364,], distr = "poisson")

#summary(pois_isocluster3)
```

```{r, echo = FALSE}
isocluster_MSE3 <- MSE_calc3(isocluster_matrix, coef(pois_isocluster3))
#isocluster_MSE3
```

```{r, echo = FALSE}
pois_all3 <- tsglm(overall_ts[1:364], model = list(past_obs = c(1,2,3)), xreg = all_matrix[1:364,], distr = "poisson")

#summary(pois_all3)
```

```{r, echo = FALSE}
all_MSE3 <- MSE_calc3(all_matrix, coef(pois_all3))
#all_MSE3
```

At this point, we also decided to check the performance when autoregressing on 1, 2, or 3 past observations. The table below lists the AIC and MSE for each model based on the number of past observations autoregressed (AIC1 represents autoregressing on 1 observation, AIC2 represents autoregressing on 2 observations, etc). Overall, it was determined that autoregressing more observations did not help much with model fit. It's clear to see that AIC and MSE values in general increased or stayed relatively the same. Thus it was decided that autoregressing on 1 observation for the 6th model incorporating all the variables was the best model fit. 

```{r, echo = FALSE}
models <- c("Cluster Variables", "Cluster with Seasons", "Source Variables", "Source with Seasons", "Cluster and Source", "Cluster, Source, and Seasons")
AIC_vals3 <- c(AIC(pois_cluster3),AIC(pois_cseason3),AIC(pois_source3),AIC(pois_isoseason3),AIC(pois_isocluster3), AIC(pois_all3))
mse3 <- c(cluster_MSE3,cseason_MSE3,source_MSE3,isoseason_MSE3,isocluster_MSE3,all_MSE3)
#medianmse <- c(median(cluster_MSE),median(cseason_MSE),median(source_MSE),median(isoseason_MSE),median(isocluster_MSE),median(all_MSE))
#sdmse <- c(sd(cluster_MSE),sd(cseason_MSE),sd(source_MSE),sd(isoseason_MSE),sd(isocluster_MSE),sd(all_MSE))
data.frame(Models = models, AIC1 = AIC_vals, AIC2 = AIC_vals2, AIC3 = AIC_vals3, MSE1 = meanmse, MSE2 = mse2, MSE3 = mse3) %>%
  kbl() %>%
  kable_styling()
```

```{r, echo = FALSE}
#sort(table(overall_ts))
```

```{r, echo = FALSE}
MSE_mean <- function(covariates, mod_coef, past_mean) {
  set.seed(0)
  #initialize MSE vector 
  MSE_vals <- c()
  #get MSE values of the forecasts for the next 6 months
  next_y <- c(overall_ts[364])
  mod_lambda <- c(past_mean)
  for (j in 0:25) {
    mod_lambda <- c(mod_lambda, mod_coef %*% c(1, next_y[j+1], mod_lambda[j+1], covariates[365+j,]))
    MSE_vals <- c(MSE_vals, (overall_ts[365+j] - mod_lambda[j+2])^2)
    next_y <- c(next_y, mod_lambda)
  }
  return(sum(MSE_vals)/length(MSE_vals))
}
```

```{r, echo = FALSE}
nbm_all <- tsglm(overall_ts[1:364], model = list(past_obs = 1), xreg = all_matrix[1:364,], distr = "nbinom")
#summary(nbm_all)
```

```{r, echo = FALSE}
nbm_MSE <- MSE_calc(all_matrix, coef(nbm_all))
#nbm_MSE
```

```{r, echo = FALSE}
nbm_all1 <- tsglm(overall_ts[1:364], model = list(past_obs = 1, past_mean = 50), xreg = all_matrix[1:364,], distr = "nbinom")
#summary(nbm_all1)
```

```{r, echo = FALSE}
nbm_MSE1 <- MSE_mean(all_matrix, coef(nbm_all1), 50)
#nbm_MSE1
```

```{r, echo = FALSE}
nbm_all2 <- tsglm(overall_ts[1:364], model = list(past_obs = 1, past_mean = 55), xreg = all_matrix[1:364,], distr = "nbinom")
#summary(nbm_all2)
```

```{r, echo = FALSE}
nbm_MSE2 <- MSE_mean(all_matrix, coef(nbm_all2), 55)
#nbm_MSE2
```

```{r, echo = FALSE}
nbm_all3 <- tsglm(overall_ts[1:364], model = list(past_obs = 1, past_mean = floor(mean(overall_ts))), xreg = all_matrix[1:364,], distr = "nbinom")
#summary(nbm_all3)
```

```{r, echo = FALSE}
nbm_MSE3 <- MSE_mean(all_matrix, coef(nbm_all3), floor(mean(overall_ts)))
#nbm_MSE3
```

Next, we checked if the model can be improved when fitting with a negative binomial distribution, since it can help with overdispersion. We fitted 4 different negative binomial models, one by itself, one autoregressing on a past conditional mean of the highest frequency weekly case number (50), one autoregressing on a past conditional mean of the second highest frequency weekly case (55), and one autoregressing on a past conditional mean of the rounded average weekly case.  Below is a table listing the AIC and MSE of each negative binomial model in addition to the best performing poisson model. We can see a clear drop in the AIC for the negative binomial model that doesn't autoregress on a past conditional mean, and having the same MSE estimate as the best performing Poisson model.

```{r, echo = FALSE}
models4 <- c("Poisson", "Neg Binomial", "Neg Binomial w/ mean = 50", "Neg Binomial w/ mean = 55", "Neg Binomial w/ mean = average")
AIC_vals4 <- c(AIC(pois_all), AIC(nbm_all), AIC(nbm_all1), AIC(nbm_all2),AIC(nbm_all3))
mse4 <- c(all_MSE, nbm_MSE, nbm_MSE1, nbm_MSE2, nbm_MSE3)
#medianmse <- c(median(cluster_MSE),median(cseason_MSE),median(source_MSE),median(isoseason_MSE),median(isocluster_MSE),median(all_MSE))
#sdmse <- c(sd(cluster_MSE),sd(cseason_MSE),sd(source_MSE),sd(isoseason_MSE),sd(isocluster_MSE),sd(all_MSE))
data.frame(Models = models4, AIC = AIC_vals4, MSE = mse4) %>%
  kbl() %>%
  kable_styling()
```


```{r, echo = FALSE}
pois_mod <- tsglm(overall_ts[1:364], model = list(past_obs = 1), xreg = all_matrix[1:364,], distr = "poisson")
nbm_mod <- tsglm(overall_ts[1:364], model = list(past_obs = 1), xreg = all_matrix[1:364,], distr = "nbinom")
```

Now we can check the performance of the best poisson and negative binomial model through forecasting the 2022 data and comparing it with the observed 2022 data. To forecast, we take the $\nu_t$ (and the dispersion parameter $\phi$ for the negative binomial model) at each timestep to simulate a random number from the corresponding poisson/negative binomial distribution. This predicted value is then incorporated for autoregression on the next $\nu_t$ value. A seed was set to make the forecasting reproducible. 

We can see from the plot below that the negative binomial model predicts spikes a lot better than the poisson model. This shows that there was overdispersion within our data. However, one should note that the poisson model seems to forecast results better on nonspikes, which could be because of the higher variance in the negative binomial model. 

```{r, echo = FALSE}
set.seed(10)
mp_counts <- c(overall_ts[312:364])
mn_counts <- c(overall_ts[312:364])
mn_lambda <- c(floor(mean(overall_ts)))
for (i in 364:415){
  mp_counts <- c(mp_counts, rpois(1,c(1, m_counts[i-311], all_matrix[i,]) %*% coef(pois_mod)))
  mn_lambda <- c(mn_lambda, coef(nbm_mod) %*% c(1, mn_counts[i-311], all_matrix[i-311,]))
  mn_counts <- c(mn_counts, rnbinom(1, size = nbm_mod$sigmasq, mu = mn_lambda[i-363]))
}
obs_counts <- c(overall_ts[312:416])

ts_final2 <- data.frame(Weeks = rep(312:416,3), Cases = c(mp_counts, mn_counts, obs_counts), Models = c(rep("Best Poisson Model", 105), rep("Best Negative Binomial Model", 105), rep("Observed", 105)))

ggplot(ts_final2, aes(x = Weeks, y = Cases, color = Models, groups = Models)) + 
  geom_point() + geom_line() + labs(title = "Forecasted Cases with Observed") + 
  theme(legend.position = "bottom") + 
  scale_x_continuous(name = "Time (in Weeks)", breaks = c(1, 53, 105, 157, 209, 261, 313, 365), 
                     labels = c("2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021"))
ggsave(filename = "ts_plot2.png", plot = ggplot(ts_final2, aes(x = Weeks, y = Cases, color = Models, groups = Models)) + 
  geom_point() + geom_line() + labs(title = "Forecasted Cases with Observed") + 
  theme(legend.position = "bottom")) + 
  scale_x_continuous(name = "Time (in Weeks)", breaks = c(1, 53, 105, 157, 209, 261, 313, 365), 
                     labels = c("2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021"))
```

Below are tables of each model's coefficients as well as their standard error and 95% confidence intervals. We can see from the confidence intervals whether each variable was significant in the model. 

For the Poisson model, we can see that overall the SNP clusters were highly significant in the model. The last SNP cluster (PDS000024656.185) was not viewed as significant by itself, but the interaction between it and the season variable was viewed as significant. We can also see that the seafood and blood isolation sources were viewed as significant, and that the interaction between meat and season as well as dairy and season were viewed as significant. However, there were many interactions between season and other variables that were not viewed as significant, which could indicate that season was overall not an important variable for the model. This model seems to indicate that the first 4 SNP clusters as well as the seafood and blood sources seem to have an association with the total number of cases. 

```{r, echo = FALSE}
pois_coef <- data.frame(summary(pois_mod)[5])
variables <- c("Intercept", "Past Observation", "PDS000000366.504", "PDS000025311.254", "PDS000024989.120", "PDS000024645.152", "PDS000024656.185","Meat Source", "Dairy Source", "Seafood Source", "Blood Source", "Season", "PDS000000366.504 * Season", "PDS000025311.254 * Season", "PDS000024989.120 * Season", "PDS000024645.152 * Season", "PDS000024656.185 * Season","Meat Source * Season", "Dairy Source * Season", "Seafood Source * Season", "Blood Source * Season")
pois_coef <- cbind(variables, pois_coef)
pois_coef %>% 
  kbl( booktabs=T, escape=T, align = "c",digits = 3, caption = "") %>% 
  kable_styling(full_width =FALSE, latex_options = c("hold_position")) %>% 
  kable_material(c("striped", "hover", "condensed"))
```

Interestingly enough, the negative binomial has every variable as insignificant, which seems to indicate that no variable is associated with the total number of cases. This is in stark difference with the Poisson model, with many significant variables. Further investigation with model selection can be done to see if there are signifiant variables within the negative binomial model.

```{r, echo = FALSE}
nbm_coef <- data.frame(summary(nbm_mod)[5])
nbm_coef <- cbind(c(variables, "Dispersion Parameter"), nbm_coef)
nbm_coef %>% 
  kbl( booktabs=T, escape=T, align = "c",digits = 3,
                caption = "") %>% 
  kable_styling(full_width =FALSE, latex_options = c("hold_position")) %>% 
  kable_material(c("striped", "hover", "condensed"))
```

Although our initial results are promising, the models themselves are not very accurate in forecasting overall case data. The Poisson model does not account for overdispersion and has trouble modelling spikes, and the negative binomial model does not predict spikes accurately enough. Thus, these models are mainly good for inference for listeria. The performance however is also due to the data itself. As mentioned earlier, spikes appear without warning, making it hard for prediction. If the data properly recorded when each case occurred (instead of when the case was reported), we would potentially see more gradual spikes, especially since we would not be dealing with batch reporting. 

# Results

In summary, we created models (Poisson autoregressive and negative binomial) to forecast the number of Listeria cases. Our model selection process of deciding fitness based on AIC and RSE led us to choosing the Cluster, Source, and Seasons model. This model had an associated AIC1 of 26624.50 and MSE1 of 125143.38.

There are several important limitations associated with the data and with the methods we performed that are important to address in contextualizing our findings. A critical limitation is the nature of the NCBI Pathogen Detection Isolation data itself. Importantly, the data variable does not represent the actual date associated with the time of the case occurring, rather it is associated with the date the isolate was created in the system. This is evident with how spikes seem to appear without warning near the end of each quarter year, which could be explaiend with scientists wanting to report their batch testing within their deadlines. Since all of our models are dependent on the weekly counts of Listeria cases, we cannot be truly certain that these are accurate or reliable estimates of the true case dates. Our modeling was limited by the variables we included. Previous literature, which we cite in the background, has used other variables that have been deemed to be relevant in forecasting or predicting cases of Listeria. An example of a variable which we did not have access to with the NCBI data but that limits our findings is the weather. Another limitation is that we conducted model selection only based on the AIC and MSE values. While it is established practice to use these measures when considering models, there could have been other measures including adjusted R squared, BIC and MDL (Minimum Description Length). Model selection like backwards and forward selection can also help with increasing model fit. 

While our project is useful in its construction of a forecasting model for cases of Listeria, there is room for future exploration and improvement. One potential future direction that could improve the applicability of this work in terms of dedicating resources and efforts to mitigating potential spread of Listeria would be the implementation of an alarm system. This alarm system could be based on the gap between observed and predicted values. For example, if the model forecasts a large gap in cases, the user receives a “ping” that indicates a potential outbreak. Another future improvement that is generally feasible would be to integrate weather data, which is known to be associated with cases of Listeria, through linking the source location with a historic data set of weather patterns. While this method is limited in its ability to be granular (i.e. county level) we do have access to state level data. It may be possible, then, to link the state level data with the weather being experienced in that region at the source date time. By doing this, we would be able to include another relevant potentially explanatory variable into the models for Listeria cases. 

# References
1. Rather IA, Koh WY, Paek WK, Lim J. The sources of chemical contaminants in food and their health implications. Frontiers in pharmacology. 2017 Nov 17;8:830.

2. World Health Organization [WHO]. (2011c). Initiative to estimate the Global Burden of Foodborne Diseases: Information and publications. Retrieved June 26, 2011, from http://www.who.int/foodsafety/foodborne_disease/ferg/en/index7.html

3. CDC. Centers for disease control and prevention, national center for emerging and zoonotic infectious diseases (NCEZID), Division of Foodborne, Waterborne, and Environmental Diseases (DFWED).

4. World Health Organization. WHO estimates of the global burden of foodborne diseases: foodborne disease burden epidemiology reference group 2007-2015. World Health Organization; 2015

5. Schlech III WF, Acheson D. Foodborne listeriosis. Clinical Infectious Diseases. 2000 Sep 1;31(3):770-5.

6. de Noordhout CM, Devleesschauwer B, Angulo FJ, Verbeke G, Haagsma J, Kirk M, Havelaar A, Speybroeck N. The global burden of listeriosis: a systematic review and meta-analysis. The Lancet Infectious Diseases. 2014 Nov 1;14(11):1073-82.

7. Pomeroy M, Conrad A, Pettengill JB, McCLURE MO, Wellman AA, Marus J, Huffman J, Wise M. Evaluation of avocados as a possible source of Listeria monocytogenes infections, United States, 2016 to 2019. Journal of Food Protection. 2021 Jul 1;84(7):1122-6.

8. Self JL, Conrad A, Stroika S, Jackson A, Whitlock L, Jackson KA, Beal J, Wellman A, Fatica MK, Bidol S, Huth PP. Multistate outbreak of listeriosis associated with packaged leafy green salads, United States and Canada, 2015–2016. Emerging infectious diseases. 2019 Aug;25(8):1461.

9. Jackson KA, Gould LH, Hunter JC, Kucerova Z, Jackson B. Listeriosis outbreaks associated with soft cheeses, United States, 1998–2014. Emerging infectious diseases. 2018 Jun;24(6):1116.

10. Collineau L, Boerlin P, Carson CA, Chapman B, Fazil A, Hetman B, McEwen SA, Parmley EJ, Reid-Smith RJ, Taboada EN, Smith BA. Integrating whole-genome sequencing data into quantitative risk assessment of foodborne antimicrobial resistance: a review of opportunities and challenges. Frontiers in Microbiology. 2019 May 21;10:1107.

11. Moura A, Tourdjman M, Leclercq A, Hamelin E, Laurent E, Fredriksen N, Van Cauteren D, Bracq-Dieye H, Thouvenot P, Vales G, Tessaud-Rita N. Real-time whole-genome sequencing for surveillance of Listeria monocytogenes, France. Emerging infectious diseases. 2017 Sep;23(9):1462.

12. Moura A, Criscuolo A, Pouseele H, Maury MM, Leclercq A, Tarr C, Björkman JT, Dallman T, Reimer A, Enouf V, Larsonneur E. Whole genome-based population biology and epidemiological surveillance of Listeria monocytogenes. Nature microbiology. 2016 Oct 10;2(2):1-0.

13. Tanui CK, Benefo EO, Karanth S, Pradhan AK. A Machine Learning Model for Food Source Attribution of Listeria monocytogenes. Pathogens. 2022 Jun 16;11(6):691.

14. Cherrie MP, Nichols G, Iacono GL, Sarran C, Hajat S, Fleming LE. Pathogen seasonality and links with weather in England and Wales: a big data time series analysis. BMC Public Health. 2018 Dec;18(1):1-3

15. Simpson R, Waskow MA, Venkat A, Zhou B, Naumova EN. Foodborne Outbreak Calendar: Applications of Time Series.

16. Imai C, Armstrong B, Chalabi Z, Mangtani P, Hashizume M. Time series regression model for infectious disease and weather. Environmental research. 2015 Oct 1;142:319-27.

17. Ismail L, Materwala H, Znati T, Turaev S, Khan MA. Tailoring time series models for forecasting coronavirus spread: Case studies of 187 countries. Computational and Structural Biotechnology Journal. 2020 Jan 1;18:2972-3206.

18. Gomez-Cravioto DA, Diaz-Ramos RE, Cantu-Ortiz FJ, Ceballos HG. Data analysis and forecasting of the COVID-19 spread: a comparison of recurrent neural networks and time series models. Cognitive Computation. 2021 Jun 3:1-2.

19.de Noordhout CM, Devleesschauwer B, Haagsma JA, Havelaar AH, Bertrand S, Vandenberg O, Quoilin S, Brandt PT, Speybroeck N. Burden of salmonellosis, campylobacteriosis and listeriosis: a time series analysis, Belgium, 2012 to 2020. Eurosurveillance. 2017 Sep 21;22(38):30615.
 Brandt PT, Williams JT. A linear Poisson autoregressive model: The Poisson AR (p) model. Political Analysis. 2001;9(2):164-84.


# Github Link

Github Repository link: https://github.com/zhejiadong/PHP2550